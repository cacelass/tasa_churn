# Churn Prediction 

Proyecto para **predecir la probabilidad de abandono de clientes** (tasa de churn) usando t√©cnicas de **Machine Learning supervisado**. El objetivo es identificar clientes con riesgo de abandonar y tomar acciones preventivas para mejorar la retenci√≥n.

---

## Descripci√≥n del problema

En muchos negocios, el **abandono de clientes** tiene un impacto directo en los ingresos y en la estabilidad del negocio. La tasa de churn mide el porcentaje de clientes que dejan de usar el servicio durante un periodo determinado.

El desaf√≠o consiste en predecir, a partir de datos hist√≥ricos y de comportamiento del cliente:

- Si un cliente es probable que abandone (churn = 1) o permanezca (churn = 0).  
- La **probabilidad de abandono** para cada cliente, no solo una predicci√≥n binaria.  

Contamos con informaci√≥n hist√≥rica sobre clientes, incluyendo:

- Datos demogr√°ficos: edad, g√©nero, segmento, antig√ºedad.  
- Datos de uso: frecuencia de compra/uso, tickets promedio, productos contratados.  
- Interacciones con el servicio: quejas, llamadas a soporte, pagos atrasados.

---

## Inicio r√°pido

### Prerequisitos

- **Python ‚â• 3.11**
- **pip** o **uv** para gesti√≥n de dependencias

### Instalaci√≥n

1. **Clona el repositorio:**
   ```bash
   git clone https://github.com/cacelass/tasa_churn
   cd tasa_churn
   ```

2. **Instala las dependencias:**
   
   Con `pip`:
   ```bash
   pip install -e .
   ```
   
   O con `uv` (recomendado):
   ```bash
   make setup
   ```

3. **Prepara los datos:**
   
   Coloca tu archivo de datos de entrenamiento en la carpeta `data/raw/` con el nombre:
   ```
   data/raw/customer_churn_dataset-training-master.csv
   ```
   
   El archivo debe contener la columna `Churn` con los valores objetivo (0 = no abandona, 1 = abandona).

### Ejecuci√≥n

**Ejecuta el programa principal:**

```bash
python main.py
```

El programa realizar√° autom√°ticamente:

1. **Entrenamiento inicial** (solo la primera vez):
   - Carga los datos desde `data/raw/`
   - Preprocesa las caracter√≠sticas (encoding y escalado)
   - Entrena m√∫ltiples modelos (RandomForest, LogisticRegression, etc.)
   - Guarda el mejor modelo en `models/`
   - Guarda los artefactos necesarios (encoders, scaler) en `models/artifacts/`

2. **Modo predicci√≥n** (en ejecuciones posteriores):
   - Carga el modelo ya entrenado
   - Solicita datos del cliente de forma interactiva
   - Valida que los datos sean correctos
   - Predice la probabilidad de churn
   - Permite evaluar m√∫ltiples clientes en la misma sesi√≥n

### Ejemplo de uso

```bash
$ python main.py

>>> Modelo no encontrado. Iniciando entrenamiento...
--> Preprocesando datos de entrenamiento...
>>> Entrenamiento finalizado.

========================================
   RIESGO DE CHURN - PREDICCI√ìN
========================================

üîπ Dato: AGE
     Introduce un n√∫mero: 35

üîπ Dato: GENDER
   Opciones v√°lidas: Female, Male
     Escribe una opci√≥n: Male

üîπ Dato: TENURE
     Introduce un n√∫mero: 24

üîπ Dato: SUBSCRIPTION TYPE
   Opciones v√°lidas: Basic, Standard, Premium
     Escribe una opci√≥n: Premium

üîπ Dato: CONTRACT LENGTH
   Opciones v√°lidas: Monthly, Quarterly, Annual
     Escribe una opci√≥n: Annual

üîπ Dato: SUPPORT CALLS
     Introduce un n√∫mero: 2

üîπ Dato: PAYMENT DELAY
     Introduce un n√∫mero: 0

------------------------------
Cliente estable (Riesgo bajo - Confianza NO churn: 87.3%)
------------------------------

¬øEvaluar otro cliente? (s/n): n
Cerrando programa...
```

---

## Estructura del proyecto

```
tasa_churn/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                          # Datos originales sin modificar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ customer_churn_dataset-training-master.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ customer_churn_dataset-testing-master.csv
‚îÇ   ‚îú‚îÄ‚îÄ interim/                      # Datos intermedios transformados
‚îÇ   ‚îú‚îÄ‚îÄ processed/                    # Datos finales para modelos
‚îÇ   ‚îî‚îÄ‚îÄ external/                     # Datos de fuentes externas
‚îÇ
‚îú‚îÄ‚îÄ models/                           # Modelos y artefactos
‚îÇ   ‚îú‚îÄ‚îÄ RandomForest.joblib          # Modelo entrenado
‚îÇ   ‚îî‚îÄ‚îÄ artifacts/                    # Encoders, scalers y configuraci√≥n
‚îÇ       ‚îú‚îÄ‚îÄ encoders.joblib
‚îÇ       ‚îú‚îÄ‚îÄ scaler.joblib
‚îÇ       ‚îî‚îÄ‚îÄ columns.joblib
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                        # Jupyter notebooks para exploraci√≥n
‚îÇ
‚îú‚îÄ‚îÄ reports/                          # Reportes y visualizaciones
‚îÇ   ‚îî‚îÄ‚îÄ figures/
‚îÇ
‚îú‚îÄ‚îÄ tests/                            # Tests unitarios
‚îÇ
‚îú‚îÄ‚îÄ tasa_churn/                       # C√≥digo fuente del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ make_dataset.py          # Carga de datos
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py        # Preprocesamiento y transformaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_model.py           # Entrenamiento de modelos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict_model.py         # Evaluaci√≥n y predicci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ paths.py                 # Gesti√≥n de rutas
‚îÇ   ‚îî‚îÄ‚îÄ visualization/
‚îÇ       ‚îî‚îÄ‚îÄ visualize.py             # Visualizaciones
‚îÇ
‚îú‚îÄ‚îÄ main.py                          # üöÄ Punto de entrada principal
‚îú‚îÄ‚îÄ pyproject.toml                   # Dependencias del proyecto
‚îú‚îÄ‚îÄ setup.py                         # Configuraci√≥n de instalaci√≥n
‚îî‚îÄ‚îÄ README.md                        # Este archivo
```

---

## Soluci√≥n propuesta

El enfoque principal es **aprendizaje supervisado**, donde entrenamos modelos con datos etiquetados (clientes que han abandonado o permanecido) para que aprendan patrones predictivos.  

### Modelos considerados

Para evaluar y seleccionar el mejor modelo, se probar√°n distintos algoritmos supervisados:

- **Logistic Regression:** proporciona probabilidades expl√≠citas y sirve como baseline.  
- **Decision Tree:** captura relaciones no lineales entre variables y es interpretable.  
- **Random Forest:** ensemble robusto que reduce overfitting y mejora precisi√≥n.  
- **K-Nearest Neighbors (KNN):** modelo simple basado en similitud entre clientes.  

### M√©tricas de evaluaci√≥n

- **Clasificaci√≥n binaria:** Accuracy, Precision, Recall, F1-score.  
- **Probabilidades de churn:** ROC-AUC, Log Loss o Brier Score para evaluar la calidad de las probabilidades.  

## Resultados del Modelo

Despu√©s de evaluar varios algoritmos (Logistic Regression, Random Forest, XGBoost), estos son los resultados obtenidos con el modelo final:

| M√©trica       | Valor  | Descripci√≥n |
| :------------ | :----: | :---------- |
| **Accuracy** | 0.81   | Precisi√≥n global del modelo. |
| **Precision** | 0.65   | Capacidad de no marcar como fuga a un cliente leal. |
| **Recall** | 0.72   | Capacidad de detectar a los clientes que realmente se van. |
| **F1-Score** | 0.68   | Balance entre precisi√≥n y recall. |
| **AUC-ROC** | 0.84   | Capacidad de distinci√≥n entre clases. |

> **Nota:** Se prioriz√≥ el **Recall** para asegurar que el departamento de retenci√≥n identifique a la mayor cantidad posible de clientes en riesgo.

### Visualizaci√≥n Clave
![An√°lisis de Importancia de Variables y Resultados](data/processed/image.png)
---

## Pipeline del proyecto

1. **Exploraci√≥n de datos:** an√°lisis de distribuciones, valores faltantes y correlaciones (`pandas`, `seaborn`, `missingno`).  
2. **Preprocesamiento:** limpieza, codificaci√≥n de variables categ√≥ricas, escalado de features, imputaci√≥n de faltantes.  
3. **Divisi√≥n train/test** y validaci√≥n cruzada para asegurar robustez.  
4. **Entrenamiento de modelos supervisados** y comparaci√≥n de desempe√±o.  
5. **Selecci√≥n del modelo final** seg√∫n m√©tricas y calibraci√≥n de probabilidades.  
6. **Interpretaci√≥n de resultados:** importancia de features, identificaci√≥n de clientes con alto riesgo de churn.  

---

## Tecnolog√≠as y librer√≠as

- **Python ‚â• 3.11**  
- **An√°lisis y visualizaci√≥n de datos:** `pandas`, `numpy`, `matplotlib`, `seaborn`, `plotly`  
- **Machine Learning:** `scikit-learn`, `lightgbm`, `xgboost`, `keras`, `tensorflow`  
- **Exploraci√≥n de datos faltantes y limpieza:** `pyjanitor`, `missingno`  
