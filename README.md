# Churn Prediction 

Proyecto para **predecir la probabilidad de abandono de clientes** (tasa de churn) usando tÃ©cnicas de **Machine Learning supervisado**. El objetivo es identificar clientes con riesgo de abandonar y tomar acciones preventivas para mejorar la retenciÃ³n.

---

## DescripciÃ³n del problema

En muchos negocios, el **abandono de clientes** tiene un impacto directo en los ingresos y en la estabilidad del negocio. La tasa de churn mide el porcentaje de clientes que dejan de usar el servicio durante un periodo determinado.

El desafÃ­o consiste en predecir, a partir de datos histÃ³ricos y de comportamiento del cliente:

- Si un cliente es probable que abandone (churn = 1) o permanezca (churn = 0).  
- La **probabilidad de abandono** para cada cliente, no solo una predicciÃ³n binaria.  

Contamos con informaciÃ³n histÃ³rica sobre clientes, incluyendo:

- Datos demogrÃ¡ficos: edad, gÃ©nero, segmento, antigÃ¼edad.  
- Datos de uso: frecuencia de compra/uso, tickets promedio, productos contratados.  
- Interacciones con el servicio: quejas, llamadas a soporte, pagos atrasados.

---

## Inicio rÃ¡pido

### Prerequisitos

- **Python â‰¥ 3.11**
- **pip** o **uv** para gestiÃ³n de dependencias

### InstalaciÃ³n

1. **Clona el repositorio:**
   ```bash
   git clone https://github.com/cacelass/tasa_churn
   cd tasa_churn
   ```

2. **Instala las dependencias:**
   
   Con `pip`:
   ```bash
   pip install -e .
   ```
   
   O con `uv` (recomendado):
   ```bash
   make setup
   ```

3. **Prepara los datos:**
   
   Coloca tu archivo de datos de entrenamiento en la carpeta `data/raw/`.

   El archivo debe contener la columna `Churn` con los valores objetivo (0 = no abandona, 1 = abandona).

### EjecuciÃ³n

**Ejecuta el programa principal:**

```bash
python main.py
```

El programa realizarÃ¡ automÃ¡ticamente:

1. **Entrenamiento inicial** (solo la primera vez):
   - Carga los datos desde `data/raw/`
   - Preprocesa las caracterÃ­sticas (encoding y escalado)
   - Entrena mÃºltiples modelos (RandomForest, LogisticRegression, etc.)
   - Guarda el mejor modelo en `models/`
   - Guarda los artefactos necesarios (encoders, scaler) en `models/artifacts/`

2. **Modo predicciÃ³n** (en ejecuciones posteriores):
   - Carga el modelo ya entrenado
   - Solicita datos del cliente de forma interactiva
   - Valida que los datos sean correctos
   - Predice la probabilidad de churn
   - Permite evaluar mÃºltiples clientes en la misma sesiÃ³n

### Ejemplo de uso

```bash
$ python main.py

>>> Modelo no encontrado. Iniciando entrenamiento...
--> Preprocesando datos de entrenamiento...
>>> Entrenamiento finalizado.

========================================
   RIESGO DE CHURN - PREDICCIÃ“N
========================================

ðŸ”¹ Dato: AGE
     Introduce un nÃºmero: 35

ðŸ”¹ Dato: GENDER
   Opciones vÃ¡lidas: Female, Male
     Escribe una opciÃ³n: Male

ðŸ”¹ Dato: TENURE
     Introduce un nÃºmero: 24

ðŸ”¹ Dato: SUBSCRIPTION TYPE
   Opciones vÃ¡lidas: Basic, Standard, Premium
     Escribe una opciÃ³n: Premium

ðŸ”¹ Dato: CONTRACT LENGTH
   Opciones vÃ¡lidas: Monthly, Quarterly, Annual
     Escribe una opciÃ³n: Annual

ðŸ”¹ Dato: SUPPORT CALLS
     Introduce un nÃºmero: 2

ðŸ”¹ Dato: PAYMENT DELAY
     Introduce un nÃºmero: 0

------------------------------
Cliente estable (Riesgo bajo - Confianza NO churn: 87.3%)
------------------------------

Â¿Evaluar otro cliente? (s/n): n
Cerrando programa...
```

---

## Estructura del proyecto

```
tasa_churn/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Datos originales sin modificar
â”‚   â”‚   â”œâ”€â”€ customer_churn_dataset-training-master.csv
â”‚   â”‚   â””â”€â”€ customer_churn_dataset-testing-master.csv
â”‚   â”œâ”€â”€ interim/                      # Datos intermedios transformados
â”‚   â”œâ”€â”€ processed/                    # Datos finales para modelos
â”‚   â””â”€â”€ external/                     # Datos de fuentes externas
â”‚
â”œâ”€â”€ models/                           # Modelos y artefactos
â”‚   â”œâ”€â”€ RandomForest.joblib          # Modelo entrenado
â”‚   â””â”€â”€ artifacts/                    # Encoders, scalers y configuraciÃ³n
â”‚       â”œâ”€â”€ encoders.joblib
â”‚       â”œâ”€â”€ scaler.joblib
â”‚       â””â”€â”€ columns.joblib
â”‚
â”œâ”€â”€ notebooks/                        # Jupyter notebooks para exploraciÃ³n
â”‚
â”œâ”€â”€ reports/                          # Reportes y visualizaciones
â”‚   â””â”€â”€ figures/
â”‚
â”œâ”€â”€ tests/                            # Tests unitarios
â”‚
â”œâ”€â”€ tasa_churn/                       # CÃ³digo fuente del proyecto
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ make_dataset.py          # Carga de datos
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ build_features.py        # Preprocesamiento y transformaciÃ³n
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ train_model.py           # Entrenamiento de modelos
â”‚   â”‚   â””â”€â”€ predict_model.py         # EvaluaciÃ³n y predicciÃ³n
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ paths.py                 # GestiÃ³n de rutas
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ visualize.py             # Visualizaciones
â”‚
â”œâ”€â”€ main.py                          # ðŸš€ Punto de entrada principal
â”œâ”€â”€ pyproject.toml                   # Dependencias del proyecto
â”œâ”€â”€ setup.py                         # ConfiguraciÃ³n de instalaciÃ³n
â””â”€â”€ README.md                        # Este archivo
```

---

## SoluciÃ³n propuesta

El enfoque principal es **aprendizaje supervisado**, donde entrenamos modelos con datos etiquetados (clientes que han abandonado o permanecido) para que aprendan patrones predictivos.  

### Modelos considerados

Para evaluar y seleccionar el mejor modelo, se probarÃ¡n distintos algoritmos supervisados:

- **Logistic Regression:** proporciona probabilidades explÃ­citas y sirve como baseline.  
- **Decision Tree:** captura relaciones no lineales entre variables y es interpretable.  
- **Random Forest:** ensemble robusto que reduce overfitting y mejora precisiÃ³n.  
- **K-Nearest Neighbors (KNN):** modelo simple basado en similitud entre clientes.  

### MÃ©tricas de evaluaciÃ³n

- **ClasificaciÃ³n binaria:** Accuracy, Precision, Recall, F1-score.  
- **Probabilidades de churn:** ROC-AUC, Log Loss o Brier Score para evaluar la calidad de las probabilidades.  

## Resultados del Modelo

DespuÃ©s de evaluar varios algoritmos (Logistic Regression, Random Forest, XGBoost), estos son los resultados obtenidos con el modelo final:

| MÃ©trica       | Valor  | DescripciÃ³n |
| :------------ | :----: | :---------- |
| **Accuracy** | 0.81   | PrecisiÃ³n global del modelo. |
| **Precision** | 0.65   | Capacidad de no marcar como fuga a un cliente leal. |
| **Recall** | 0.72   | Capacidad de detectar a los clientes que realmente se van. |
| **F1-Score** | 0.68   | Balance entre precisiÃ³n y recall. |
| **AUC-ROC** | 0.84   | Capacidad de distinciÃ³n entre clases. |

### Insights del modelo:

Las variables mÃ¡s importantes segÃºn el modelo son: tenure, payment_delay y subscription_type. Esto indica que la antigÃ¼edad y los retrasos en pagos son los factores mÃ¡s determinantes para churn.

Clientes con pagos atrasados frecuentes y contratos mÃ¡s cortos tienen mayor riesgo de abandonar.

Este anÃ¡lisis permite priorizar estrategias de retenciÃ³n, enfocÃ¡ndose en clientes con alto riesgo segÃºn estas variables clave.
### VisualizaciÃ³n Clave
![AnÃ¡lisis de Importancia de Variables y Resultados](data/processed/image.png)
---

## Pipeline del proyecto

1. **ExploraciÃ³n de datos:** anÃ¡lisis de distribuciones, valores faltantes y correlaciones (`pandas`, `seaborn`, `missingno`).  
2. **Preprocesamiento:** limpieza, codificaciÃ³n de variables categÃ³ricas, escalado de features, imputaciÃ³n de faltantes.  
3. **DivisiÃ³n train/test** y validaciÃ³n cruzada para asegurar robustez.  
4. **Entrenamiento de modelos supervisados** y comparaciÃ³n de desempeÃ±o.  
5. **SelecciÃ³n del modelo final** segÃºn mÃ©tricas y calibraciÃ³n de probabilidades.  
6. **InterpretaciÃ³n de resultados:** importancia de features, identificaciÃ³n de clientes con alto riesgo de churn.  

---

## TecnologÃ­as y librerÃ­as

- **Python â‰¥ 3.11**  
- **AnÃ¡lisis y visualizaciÃ³n de datos:** `pandas`, `numpy`, `matplotlib`, `seaborn`, `plotly`  
- **Machine Learning:** `scikit-learn`, `lightgbm`, `xgboost`, `keras`, `tensorflow`  
- **ExploraciÃ³n de datos faltantes y limpieza:** `pyjanitor`, `missingno`  
